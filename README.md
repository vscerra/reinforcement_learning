# ğŸš€ Reinforcement Learning: Multi-Armed Bandit Experiments

This repository contains **modular implementations** of **multi-armed bandit algorithms**, inspired by Sutton & Bartoâ€™s *Reinforcement Learning: An Introduction*. The project is structured to support **parameter tuning, experimentation, and visualization** of different bandit algorithms.

---

## ğŸ“‚ Project Structure

```
reinforcement_learning/
â”‚â”€â”€ reinforcement_learning/  # Main package folder
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ bandit.py            # Bandit environment
â”‚   â”œâ”€â”€ algorithms/          # Bandit algorithms
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ algorithms.py    # Epsilon-Greedy, UCB, Gradient Bandit, etc.
â”‚   â”œâ”€â”€ experiment/          # Experiment framework
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ experiment.py
â”‚   â”œâ”€â”€ plots/               # Visualization functions
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ plots.py
â”‚â”€â”€ main.py                  # Runs experiments & visualizes results
â”‚â”€â”€ requirements.txt          # Dependencies (numpy, matplotlib, etc.)
â”‚â”€â”€ README.md                 # Project documentation
â”‚â”€â”€ .gitignore                # Ignore unnecessary files
```

---

## ğŸ“– Implemented Algorithms

### âœ… **1. Epsilon-Greedy Algorithm**
- Balances exploration and exploitation by selecting a **random action** with probability \( \epsilon \), otherwise choosing the **best-known action**.

### âœ… **2. Upper Confidence Bound (UCB)**
- Uses a confidence bonus to encourage exploration:
  \[
  A_t = \arg\max_a \left[ \hat{Q}_t(a) + c \sqrt{\frac{2 \ln t}{N_t(a)}} \right]
  \]
- Higher \( c \) means **more exploration**.

### âœ… **3. Gradient Bandit Algorithm**
- Uses **softmax action preferences** to **dynamically adapt** to the reward distribution.

---

## ğŸš€ How to Run Experiments

### ğŸ“Œ **1. Install Dependencies**
Ensure Python 3+ is installed, then run:
```bash
pip install -r requirements.txt
```

### ğŸ“Œ **2. Run the Main Experiment Script**
Execute:
```bash
python main.py
```
This runs the **multi-armed bandit simulations**, testing different algorithms **with various parameter values**.

---

## ğŸ“Š Parameter Tuning & Visualization

### ğŸ“Œ **Modify `main.py` to Tune Parameters**
- **Epsilon-Greedy:** Adjust `epsilons = [0, 0.01, 0.1, 0.3, 0.5]`
- **UCB:** Modify `c_values = [0.1, 1, 2, 5]`
- **Gradient Bandit:** Change `alphas = [0.01, 0.1, 0.4]`

---

## ğŸ›  Future Improvements
âœ… Implement **Thompson Sampling**  
âœ… Extend to **non-stationary environments**  
âœ… Add **grid search for hyperparameter tuning**  

---

## ğŸ“œ License
This project is open-source under the **MIT License**.

---

## â­ï¸ Acknowledgments
- **Sutton & Barto** for *Reinforcement Learning: An Introduction* ğŸ“–  
- **OpenAI, DeepMind, and RL Research Communities** ğŸ§   

\
